{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#Importing libraries: \n",
    "from PIL import Image\n",
    "import random, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "from matplotlib import cm\n",
    "\n",
    "import sys\n",
    "sys.path.append('/')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from grad_cam import GradCam,GuidedBackpropReLUModel,show_cams,show_gbs,preprocess_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate masks for all images in folder:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#Data used to generate the segmentation masks:\n",
    "source_dir = '/medico2021test'\n",
    "image_files = os.listdir(source_dir)\n",
    "#Target folder for final segmentation masks:\n",
    "target_folder = '/medico2021mask'\n",
    "#The name of the model:\n",
    "model_name = '../models/run1.pt'\n",
    "\n",
    "#Define layer number to extract gradcam heat maps from, depending on run:\n",
    "if '1' in model_name or '3' in model_name:\n",
    "    layer_number = '14'\n",
    "elif '2' in model_name:\n",
    "    layer_number = '13'\n",
    "elif '4' in model_name:\n",
    "    layer_number = '20'\n",
    "else:\n",
    "    layer_number = '22'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mask_dic_list = []\n",
    "for _image in image_files:\n",
    "    #Load the model\n",
    "    model = EfficientNet.from_name('efficientnet-b1')\n",
    "    for params in model.parameters():\n",
    "        params.requires_grad = True\n",
    "    #Add extra steps for last layer and correct number of classes (=1):\n",
    "    in_ftrs = model._fc.in_features\n",
    "    model._fc = nn.Linear(in_ftrs, 1)\n",
    "    loaded_model = model\n",
    "    #Load the model file:\n",
    "    loaded_model.load_state_dict(torch.load(model_name))\n",
    "    \n",
    "    #Generate gradcam:\n",
    "    image_path = os.path.join(source_dir, _image)\n",
    "    grad_cam = GradCam(model=loaded_model, blob_name = '_blocks', target_layer_names=[layer_number], use_cuda=False)\n",
    "    img = cv2.imread(image_path, 1)\n",
    "    img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "    inputs = preprocess_image(img)\n",
    "    #Set target as None-> will select target with highest probability\n",
    "    target_index = None \n",
    "    mask_dic = grad_cam(inputs, target_index)\n",
    "    mask_dic_list.append(mask_dic)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#For model with 250 clusters, we use wider thresholds for the segmentation masks:\n",
    "if '4' in model_name or '5' in model_name:\n",
    "    segmentation_dic_list = []\n",
    "    for _dic in mask_dic_list:\n",
    "        new_dic = _dic[layer_number].copy()\n",
    "        for _l in range(len(_dic[layer_number])):\n",
    "            for _p in range(len(_dic[layer_number][_l])):\n",
    "                if _dic[layer_number][_l][_p] > 0.28 :\n",
    "                    new_dic[_l][_p] = 1\n",
    "                else:\n",
    "                    new_dic[_l][_p] = 0\n",
    "        new_dic = {layer_number:new_dic}\n",
    "        segmentation_dic_list.append(new_dic)\n",
    "else:\n",
    "    #For model with 50 or 200 clusters (narrow threshold):\n",
    "    segmentation_dic_list = []\n",
    "    for _dic in mask_dic_list:\n",
    "        new_dic = _dic[layer_number].copy()\n",
    "        for _l in range(len(_dic[layer_number])):\n",
    "            for _p in range(len(_dic[layer_number][_l])):\n",
    "                if _dic[layer_number][_l][_p] > 0.4 and _dic[layer_number][_l][_p] < 0.7:\n",
    "                    new_dic[_l][_p] = 1\n",
    "                else:\n",
    "                    new_dic[_l][_p] = 0\n",
    "        new_dic = {layer_number:new_dic}\n",
    "        segmentation_dic_list.append(new_dic)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the segmentation masks in a folder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "for s in range(len(segmentation_dic_list)):\n",
    "    #Dimensions of original image:\n",
    "    orig_image = cv2.imread(source_dir + '/' +image_files[s], 1)\n",
    "    height, width, channels = orig_image.shape\n",
    "    #Convert the segmentation mask to PIL image\n",
    "    im = Image.fromarray(np.uint8(cm.gist_earth(segmentation_dic_list[s][layer_number])*255))\n",
    "    #Resize\n",
    "    im = im.resize((width,height), Image.ANTIALIAS)\n",
    "    #Save in target folder:\n",
    "    im = im.save(target_folder + '/' + image_files[s][:-4] + '.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}